{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae2595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0baf0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7116\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6130\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2596\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1676\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1346\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1102\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0892\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.0719\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0625\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0536\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0502\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0453\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0419\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0388\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0365\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0340\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0319\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0299\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0282\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0266\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0250\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0235\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0224\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0210\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0196\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0188\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0175\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0162\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0155\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0142\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0136\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0126\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0118\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0111\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0027\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0177\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0240\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0235\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0165\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0148\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0041\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0019\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9930\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9942\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9992\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9895\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9887\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9885\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9884\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9881\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9876\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9871\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9867\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9865\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9862\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9859\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9858\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9856\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9853\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9851\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9849\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9847\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9846\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9844\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9842\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9841\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9839\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9838\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9837\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9836\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9835\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9834\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9833\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9832\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9830\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9829\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9828\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9826\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9827\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.825 - 0s 3ms/step - loss: 3.9825\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9824\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9824\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9823\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9822\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9822\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9821\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9820\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9819\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9819\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9818\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9817\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9817\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9816\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9815\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9815\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9815\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9814\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9813\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9813\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9812\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9812\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9811\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9811\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9811\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9810\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9810\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9810\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9809\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9809\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9808\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9808\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9808\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9807\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9807\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9807\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9807\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9806\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9806\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9806\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9806\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9805\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9805\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9805\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9805\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9804\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9804\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9804\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9804\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9804\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9803\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9803\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9803\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9803\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9803\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9803\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9802\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9802\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.853 - 0s 4ms/step - loss: 3.9802\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9802\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9802\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9802\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9801\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9801\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9801\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9801\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9801\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9801\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9801\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9801\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9800\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[2.3618746 0.        2.6321952 1.4680724 2.486276  2.599362  0.\n",
      " 2.821429  2.0575635 2.5261514 0.        0.        2.086247  0.\n",
      " 1.3211935 2.2570515 0.        2.2505856 0.        2.2567792 2.04199\n",
      " 0.        2.7031913 0.        1.0224292 1.8073642 2.381851  1.8998973\n",
      " 2.068422  1.8973832 1.2470666 2.2859068 2.0092013 3.0836709 0.\n",
      " 2.3997116 2.2808788 1.0143952 0.        0.        0.        0.\n",
      " 0.        1.0283515 0.        0.        2.4722    2.405992  2.562718\n",
      " 2.1209164 2.021154  0.        0.        0.        0.        1.4270134\n",
      " 0.        0.        0.        0.        0.        2.2641654 0.\n",
      " 2.5347338 1.9827405 3.0552313 1.3939062 1.4405771 0.        0.\n",
      " 0.        0.        0.        0.        0.        2.4140868 2.3001013\n",
      " 1.9497689 0.        0.        2.506636  2.4606206 2.7714024 2.165278\n",
      " 0.        0.        0.        1.530573  0.        0.        0.\n",
      " 1.056058  1.024645  2.4483316 2.6611025 2.5601566 0.        2.520457\n",
      " 0.        1.3839688 1.1429536 0.        0.        0.        0.\n",
      " 0.        0.        0.7838165 2.5668855 0.        2.750293  2.6057582\n",
      " 2.239556  2.6064599 0.        1.8498908 0.        0.        0.\n",
      " 0.        2.1162798 0.        0.        1.2243912 2.3869727 2.2071722\n",
      " 1.3601159 0.        2.3142593 2.0077283 1.1857654 0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        3.2706187 2.8569417 0.        0.        1.1950203 1.0709648\n",
      " 1.2559263 1.3337243 1.0311052 0.        0.        0.        0.\n",
      " 0.        1.0581194 0.        2.8518112 2.6649358 0.        0.\n",
      " 3.0741756 2.413913  1.1837015 1.0120995 0.        0.        0.\n",
      " 0.        0.        0.        1.0355322 1.0548103 1.551028  0.\n",
      " 0.        2.8244739 2.9515426 0.        1.224034  0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        1.8324261\n",
      " 1.5469712 1.7635012 0.        2.99677   2.4131808 2.2679753 1.5812244\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        2.600985  0.        2.4720004 0.        2.5431907 2.4555044\n",
      " 2.4899702 2.5315235 1.1420017 1.0809202 1.0167799 0.        0.\n",
      " 2.189805  2.5775402 2.4367905 0.        0.        2.4550214 0.\n",
      " 2.2341533 0.        1.4262564 2.5276394 2.4058433 0.        0.\n",
      " 0.        1.7931724 0.        0.        0.        0.        0.\n",
      " 2.1554518 0.        2.1717558 2.3578463 1.8870678 2.3955557 2.2705185\n",
      " 1.8327631 1.8989674 1.4328712 2.612242  0.        1.7059883 0.\n",
      " 0.        2.5492384 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "from math import *\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import numpy\n",
    "\n",
    "def toBlackWhiteBinary(img):\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if img[i][j] != 255:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def makeBinaryImages():                \n",
    "    for i in range(10):\n",
    "        path = list(r\"C:\\Users\\billy_000\\Documents\\UF\\Neural Networks\\Assign1\\Neural-Networks-Assignment-1\\Assignment1\\images\\x.PNG\")\n",
    "        path[104] = str(i)\n",
    "        path = \"\".join(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = toBlackWhiteBinary(img)\n",
    "        cv2.imwrite(path, img)\n",
    "        \n",
    "def ImageToArray(img):\n",
    "    final = []\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            final.append(img[i][j])\n",
    "            \n",
    "    for i in range(len(final)):\n",
    "        if final[i] == 255:\n",
    "            final[i] = 1\n",
    "        else:\n",
    "            final[i] = 0\n",
    "    return final\n",
    "\n",
    "def compareImage(Original, Output):\n",
    "    mismatch = 0\n",
    "    for i in range(len(Original)):\n",
    "        if (Output[i] - 0.1) < Original[i]:\n",
    "            mismatch += 1\n",
    "    return mismatch / len(Original)\n",
    "\n",
    "def DataSetOfAllImages():\n",
    "    dataset = []\n",
    "    for i in range(10):\n",
    "        path = list(r\"C:\\Users\\billy_000\\Documents\\UF\\Neural Networks\\Assign1\\Neural-Networks-Assignment-1\\Assignment1\\images\\x.PNG\")\n",
    "        path[104] = str(i)\n",
    "        path = \"\".join(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        dataset.append(ImageToArray(img))\n",
    "    return dataset\n",
    "        \n",
    "X = numpy.array(DataSetOfAllImages())\n",
    "y = X\n",
    "    \n",
    "def Model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim = 256, activation='relu'))\n",
    "    #model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=150, batch_size=2, verbose = True)\n",
    "\n",
    "    \n",
    "    print(X[1])\n",
    "    newY = model.predict(X)\n",
    "    print(newY[1])\n",
    "    \n",
    "\n",
    "Model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23fa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21a639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
